{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "import sys\n",
    "import keras\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, LSTM, Bidirectional,Multiply \n",
    "# Merge, \n",
    "from keras.layers import BatchNormalization, merge, add\n",
    "from keras.layers.core import Flatten, Reshape\n",
    "from keras.layers.merge import Concatenate, concatenate, subtract, multiply\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D, AveragePooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "\n",
    "from keras.optimizers import Adam,  RMSprop\n",
    "\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.layers import Input, CuDNNGRU, GRU\n",
    "from numpy import linalg as LA\n",
    "import scipy\n",
    "from keras import backend as K\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auroc(y_true, y_pred):\n",
    "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Lambda,Add, CuDNNGRU,TimeDistributed, Bidirectional,Softmax\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "smilen = 256\n",
    "hidden_dim = 256\n",
    "\n",
    "\n",
    "def se_block(input, channels, r=8):\n",
    "    # Squeeze\n",
    "    #print(\"-------\")\n",
    "    x = GlobalAveragePooling1D()(input)\n",
    "    #print(x.shape)\n",
    "    # Excitation\n",
    "    x = Dense(channels//r, activation=\"relu\")(x)\n",
    "    #print(x.shape)\n",
    "    x = Dense(channels, activation=\"sigmoid\")(x)\n",
    "    #print(x.shape)\n",
    "    #print(\"-------\")\n",
    "    return Multiply()([input, x])\n",
    "\n",
    "\n",
    "def conv_block(inputs, seblock, NUM_FILTERS,FILTER_LENGTH1):\n",
    "    conv1_encode = Conv1D(filters=NUM_FILTERS, kernel_size=FILTER_LENGTH1,   activation='relu', padding='valid', strides=1)(inputs)\n",
    "    conv1_encode = BatchNormalization()(conv1_encode)\n",
    "    if seblock: \n",
    "        conv1_encode = se_block(conv1_encode,NUM_FILTERS)\n",
    "    \n",
    "    return conv1_encode\n",
    "\n",
    "    \n",
    "def build_model(): \n",
    "    drugInput = Input(shape=(smilen,hidden_dim))\n",
    "    \n",
    "    seblock = True \n",
    "    NUM_FILTERS = 512\n",
    "    FILTER_LENGTH1 = 5\n",
    "    n_layers = 4\n",
    "\n",
    "    encode_smiles = conv_block(drugInput, seblock, NUM_FILTERS,FILTER_LENGTH1) \n",
    "    encode_smiles = GlobalMaxPooling1D()(encode_smiles)  \n",
    "    encode_smiles = Dropout(0.5)(encode_smiles)\n",
    "    \n",
    "    FC1 = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01))(encode_smiles)\n",
    "    \n",
    "    predictions = Dense(2, kernel_initializer='normal', activation='softmax')(FC1)\n",
    "    \n",
    "    interactionModel = Model(inputs=[drugInput], outputs=[predictions])\n",
    "    opt = Adam(lr=0.001)\n",
    "    interactionModel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[auroc])\n",
    "    return interactionModel\n",
    "\n",
    "model = build_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load(\"../../dataset_new/BBBP_train_x_full.npy\",allow_pickle=True)\n",
    "train_y = np.load(\"../../dataset_new/BBBP_train_y_full.npy\",allow_pickle=True)\n",
    "valid_x = np.load(\"../../dataset_new/BBBP_valid_x_full.npy\",allow_pickle=True)\n",
    "valid_y = np.load(\"../../dataset_new/BBBP_valid_y_full.npy\",allow_pickle=True)\n",
    "test_x = np.load(\"../../dataset_new/BBBP_test_x_full.npy\",allow_pickle=True)\n",
    "test_y = np.load(\"../../dataset_new/BBBP_test_y_full.npy\",allow_pickle=True)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(len(train_y))\n",
    "print(len(valid_y))\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 运行五次\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curve')\n",
    "\n",
    "roc_aucs = []\n",
    "for i in range(5):\n",
    "    save_model_name = f'models_FP-BERT_BBBP_TT2_run{i+1}_new_L50'\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    save_checkpoint = ModelCheckpoint(save_model_name, verbose=1,\n",
    "                                      save_best_only=True, \n",
    "                                      monitor='val_loss', \n",
    "                                      save_weights_only=True, mode='min') \n",
    "    earlyStopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1,mode='min')\n",
    "    lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=50, mode='min', verbose=1)\n",
    "\n",
    "    model.fit(x=train_x, y=train_y, batch_size=256, epochs=1000, verbose=1, validation_data=(valid_x,valid_y), callbacks=[earlyStopping, save_checkpoint, lr_reduce])\n",
    "\n",
    "    model.load_weights(save_model_name)\n",
    "    y_pred = model.predict([test_x])\n",
    "    roc_auc = roc_auc_score(test_y, y_pred, average='weighted')\n",
    "    print(roc_auc)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    \n",
    "    Y_pred_0 = [y[0] for y in y_pred]  # 取出y中的一列\n",
    "    Y_0 = [y[0] for y in test_y]\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve\n",
    "\n",
    "    fpr, tpr, thresholds_keras = roc_curve(Y_0, Y_pred_0, drop_intermediate=False)   \n",
    "    plt.figure()\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    plt.savefig(f\"ROC-Curve_BBBP_FP-BERT_run{i+1}.png\")\n",
    "    plt.show()\n",
    "    np.save(f'BBBP_FP-BERT_FPR_run{i+1}_L_f',fpr)\n",
    "    np.save(f'BBBP_FP-BERT_TPR_run{i+1}_L_f',tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_aucs,np.mean(roc_aucs),np.std(roc_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
